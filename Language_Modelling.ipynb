{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Language Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pTsqLwfeZEEX",
        "UZxkeP_MZSKa"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VpBi_MlhGMi"
      },
      "source": [
        "# Language Modeling and Lyrics Generation\n",
        "3 models are built for 3 most frequent genres to generate lyrics\n",
        "A statistical model is built using bigram and the results are compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYPH4sJ98vMO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hWf68vLVp3E",
        "outputId": "bec163a6-b45f-4cb9-ae6a-bb4ade4a053a"
      },
      "source": [
        "#https://drive.google.com/file/d/1u-bq8vYG8BMT-szSoDiCpdkiO_8NNIS5/view?usp=sharing\n",
        "!gdown --id \"1u-bq8vYG8BMT-szSoDiCpdkiO_8NNIS5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1u-bq8vYG8BMT-szSoDiCpdkiO_8NNIS5\n",
            "To: /content/final.csv\n",
            "675MB [00:03, 221MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxsmee6A8vMQ"
      },
      "source": [
        "CLEANED_FILE_PATH = './final.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bLOMzSt-8vMR",
        "outputId": "26203074-6981-4807-afbe-9bd07e794d95"
      },
      "source": [
        "cleaned_data = pd.read_csv(CLEANED_FILE_PATH)\n",
        "cleaned_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Language</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>cleanedlyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12 stones</td>\n",
              "      <td>world so cold</td>\n",
              "      <td>Rock</td>\n",
              "      <td>en</td>\n",
              "      <td>It starts with pain, followed by hate\\nFueled ...</td>\n",
              "      <td>it start with pain follow by hate fuel by the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12 stones</td>\n",
              "      <td>broken</td>\n",
              "      <td>Rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Freedom!\\nAlone again again alone\\nPatiently w...</td>\n",
              "      <td>freedom alon again again alon patient wait by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12 stones</td>\n",
              "      <td>3 leaf loser</td>\n",
              "      <td>Rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Biting the hand that feeds you, lying to the v...</td>\n",
              "      <td>bite the hand that feed you lie to the voic in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12 stones</td>\n",
              "      <td>anthem for the underdog</td>\n",
              "      <td>Rock</td>\n",
              "      <td>en</td>\n",
              "      <td>You say you know just who I am\\nBut you can't ...</td>\n",
              "      <td>you say you know just who i am but you cant im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12 stones</td>\n",
              "      <td>adrenaline</td>\n",
              "      <td>Rock</td>\n",
              "      <td>en</td>\n",
              "      <td>My heart is beating faster can't control these...</td>\n",
              "      <td>my heart is beat fast cant control these feel ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Artist  ...                                      cleanedlyrics\n",
              "0  12 stones  ...  it start with pain follow by hate fuel by the ...\n",
              "1  12 stones  ...  freedom alon again again alon patient wait by ...\n",
              "2  12 stones  ...  bite the hand that feed you lie to the voic in...\n",
              "3  12 stones  ...  you say you know just who i am but you cant im...\n",
              "4  12 stones  ...  my heart is beat fast cant control these feel ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7V-y4jygvY2"
      },
      "source": [
        "cleaned_data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVP3CyttglHK"
      },
      "source": [
        "genres_count = cleaned_data.groupby('Genre')['Genre'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9Xah-MglHK"
      },
      "source": [
        "top_3_genres = genres_count.nlargest(3).reset_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCDJaIpVglHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645421a9-ecbf-4958-f90c-7efb043b9ebc"
      },
      "source": [
        "top_3_genres"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.reset_index of Genre\n",
              "Rock     121390\n",
              "Pop      108693\n",
              "Metal     20286\n",
              "Name: Genre, dtype: int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R002TsJhg9Hj"
      },
      "source": [
        "# Top 3 genres are Rock Pop and Metal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTsqLwfeZEEX"
      },
      "source": [
        "## Metal Genre \n",
        "#### Run-time ~ 5-10 mins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KqvEvaU8vMS"
      },
      "source": [
        "lyric_metal = cleaned_data['cleanedlyrics'].loc[(cleaned_data['Genre']=='Metal')&(cleaned_data['Language']=='en')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWG7fN0p8vMS"
      },
      "source": [
        "lyric_metal = lyric_metal.str.cat(sep=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsJWS4Mx8vMT",
        "outputId": "285d8381-0b0d-4030-d923-7bdbd9f84aa9"
      },
      "source": [
        "print(f'Length of text: {len(lyric_metal)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 19226774 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oWaFhD6R8vMT",
        "outputId": "aff4deb5-d109-49b5-bcf8-1a88fb9b5ba8"
      },
      "source": [
        "lyric_metal[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a hundr day have made me old sinc the last time th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrZBcg8F8vMT",
        "outputId": "fa053812-8afd-48bc-ad75-c95dbc9a2e5f"
      },
      "source": [
        "# exract an ordered vocabulary - this will be letters, some numbers etc. \n",
        "vocab = sorted(set(lyric_metal))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGqCyADV8vMT"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKihGUij8vMU"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGlIGTpX8vMU"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqOkC_ql8vMU",
        "outputId": "8eac8883-ecde-4a39-9dc0-357406505231"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(lyric_metal, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(19226774,), dtype=int64, numpy=array([ 3,  2, 10, ..., 17, 17, 10])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zweM3a2G8vMU"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW4XT1Ay8vMV"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(lyric_metal)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpH8Cr4s8vMV"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdXz-RJu8vMV"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XME-nbS88vMV"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2J5W4Ux8vMV",
        "outputId": "b007adb7-8f4b-49da-ea9c-44faa01c3e88"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'a hundr day have made me old sinc the last time that i saw your pretti face a thousand lie have made'\n",
            "Target: b' hundr day have made me old sinc the last time that i saw your pretti face a thousand lie have made '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EakUuvE78vMW",
        "outputId": "a40e4fc9-fa3f-44d4-adc1-7bb1ab665882"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((256, 100), (256, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR7J25DC8vMW"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ51aE4i8vMW"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIbs38I88vMW"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUwvtEvuBQA3",
        "outputId": "a280cb2b-5516-4c48-adb5-d4f7800af6b2"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 100, 51) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5KaWS3X8vMX",
        "scrolled": false,
        "outputId": "29e16b1a-ff85-49df-971f-540e666e26b7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  13056     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  52275     \n",
            "=================================================================\n",
            "Total params: 4,003,635\n",
            "Trainable params: 4,003,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1BLP_f58vMX"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6nUYnCX8vMX"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz1SHOk88vMX"
      },
      "source": [
        "EPOCHS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Jxj9uD8vMY",
        "outputId": "ab50debd-fe85-4525-c2fa-24a10e89c2b0"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS,callbacks=[checkpoint_callback],verbose=1)\n",
        "print(\"training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "743/743 [==============================] - 146s 194ms/step - loss: 2.1817\n",
            "Epoch 2/2\n",
            "743/743 [==============================] - 148s 198ms/step - loss: 1.2630\n",
            "training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNtm8R7yR9SU"
      },
      "source": [
        "def generate_one_step(model, inputs, states=None, temperature = 1):\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "        skip_ids = ids_from_chars(['', '[UNK]'])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "            # Put a -inf at each bad index.\n",
        "            values=[-float('inf')]*len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            # Match the shape to the vocabulary\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "        prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "        \n",
        "    # Convert strings to token IDs.\n",
        "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "        input_ids = ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        # Run the model.\n",
        "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "        predicted_logits, states = model(inputs=input_ids, states=states,\n",
        "                                              return_state=True)\n",
        "        # Only use the last prediction.\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits/temperature\n",
        "        # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "        predicted_logits = predicted_logits + prediction_mask\n",
        "\n",
        "        # Sample the output logits to generate token IDs.\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "        # Convert from token ids to characters\n",
        "        predicted_chars = chars_from_ids(predicted_ids)\n",
        "\n",
        "        # Return the characters and model state.\n",
        "        return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaMBnuMyUuQd",
        "outputId": "8c9dde35-ed88-4e42-96dc-6f1ea1639d07"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['dance'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "    next_char, states = generate_one_step(model, next_char, states=states)\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([b'dancen sleep turn away from hi lyfitim ankow joy the show down now i tell thi night is fruzin begrie glow on i didnt need a toot in me not hold our hope it hurt feel enough and if is let get realli just a littl bite on cold street at deceas and pain they step malestim unfold it life is done miceri chanc but they catch me with it get betray weak the fresh is in faith is thi cattl secreci two behold dri it to desarv repent men but baggag te a tool be after wrong their ingani man crawl overdustain rminesion live lit trembebl onc age we will end over anoth night destind manifest monstrvist drive by their knee and the moon these bite of the earth they seek assam no one spot hi keeph so far stop their land of beast romain pumpin poison rule cant will be frustrat a culsul depend come inscroudlin fall scorn and cunt as i came tri to pay you but still i am i what left to spread in mind what you do what i remeng i pay fade i rememb i am uni beyond that it hope i shall prey i seek im in the belief i s'], shape=(1,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.678609609603882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZxkeP_MZSKa"
      },
      "source": [
        "## Rock Genre\n",
        "#### Run-time ~ 15-20 mins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrRW-2BxZSKb"
      },
      "source": [
        "lyric_rock = cleaned_data['cleanedlyrics'].loc[(cleaned_data['Genre']=='Rock')&(cleaned_data['Language']=='en')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-DksgLiZ1Z3",
        "outputId": "fe8ba602-d1dd-4c84-f77f-0364ee1736fa"
      },
      "source": [
        "lyric_rock"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         it start with pain follow by hate fuel by the ...\n",
              "1         freedom alon again again alon patient wait by ...\n",
              "2         bite the hand that feed you lie to the voic in...\n",
              "3         you say you know just who i am but you cant im...\n",
              "4         my heart is beat fast cant control these feel ...\n",
              "                                ...                        \n",
              "290086    your a shoot star that is what you are you bro...\n",
              "290093    life live alon on top of a hill tonight the mo...\n",
              "290103    too much inform for our mind to comprehend thi...\n",
              "290104    a monster use to chase me use to jump from the...\n",
              "290123    what all thi space junk these gem behind my ey...\n",
              "Name: cleanedlyrics, Length: 107144, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vdZcp-IZSKb"
      },
      "source": [
        "lyric_rock= lyric_rock.str.cat(sep=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KtbkZ1jZSKc",
        "outputId": "57e8fab8-42c7-4874-882e-5839da9be40c"
      },
      "source": [
        "print(f'Length of text: {len(lyric_rock)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 99948513 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rpc4wAuCZSKd",
        "outputId": "c4416e5f-a3e2-4228-9c8a-90f6b6f47bc2"
      },
      "source": [
        "lyric_rock[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'it start with pain follow by hate fuel by the endl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v8XwgqPZSKd",
        "outputId": "92cdf67a-0a85-4543-8d01-fb0de228aee3"
      },
      "source": [
        "# exract an ordered vocabulary - this will be letters, some numbers etc. \n",
        "vocab = sorted(set(lyric_rock))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA7TBf7eZSKn"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie_BDp-PZSKn"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sks5lzCcZSKn"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-WIUowwZSKn",
        "outputId": "e0b963c8-d8bb-498d-ee96-d43f040f9bb3"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(lyric_rock, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(99948513,), dtype=int64, numpy=array([11, 22,  2, ...,  7,  3, 14])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLgNSJE5ZSKo"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stPUdPY0ZSKp"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(lyric_rock)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RYVmZAIZSKp"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WRxgcVTZSKp"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rbZW87IZSKp"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e29L1BRfZSKp",
        "outputId": "b422ea85-8c16-4eca-8761-8de7587f377a"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'it start with pain follow by hate fuel by the endless question no one can answer a stain cover your '\n",
            "Target: b't start with pain follow by hate fuel by the endless question no one can answer a stain cover your h'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WMaZiCAZSKq",
        "outputId": "132946e7-f0f7-404a-ca10-1e01a0ea31c5"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((256, 100), (256, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22u2oHbNZSKq"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFX4LIXEZSKq"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5qXIif5ZSKq"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-Mnk8EHZSKq",
        "outputId": "7c5648bb-cd14-408c-be99-f5c2992b9241"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 100, 61) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "scrolled": false,
        "id": "FJFP43VYZSKr",
        "outputId": "45f24066-1e2f-4c2c-e9be-59b231060f05"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  15616     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  62525     \n",
            "=================================================================\n",
            "Total params: 4,016,445\n",
            "Trainable params: 4,016,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPHcXc9yZSKr"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-bY6HISZSKr"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7K6ljoxZSKr"
      },
      "source": [
        "EPOCHS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcCpJOprZSKr",
        "outputId": "6f57cbc1-ae14-4413-9b4f-08f51148a29e"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS,callbacks=[checkpoint_callback],verbose=1)\n",
        "print(\"training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "3865/3865 [==============================] - 770s 199ms/step - loss: 1.5741\n",
            "Epoch 2/2\n",
            "3865/3865 [==============================] - 767s 198ms/step - loss: 1.1282\n",
            "training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4-hS7YjZSKr"
      },
      "source": [
        "def generate_one_step(model, inputs, states=None, temperature = 1):\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "        skip_ids = ids_from_chars(['', '[UNK]'])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "            # Put a -inf at each bad index.\n",
        "            values=[-float('inf')]*len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            # Match the shape to the vocabulary\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "        prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "        \n",
        "    # Convert strings to token IDs.\n",
        "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "        input_ids = ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        # Run the model.\n",
        "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "        predicted_logits, states = model(inputs=input_ids, states=states,\n",
        "                                              return_state=True)\n",
        "        # Only use the last prediction.\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits/temperature\n",
        "        # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "        predicted_logits = predicted_logits + prediction_mask\n",
        "\n",
        "        # Sample the output logits to generate token IDs.\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "        # Convert from token ids to characters\n",
        "        predicted_chars = chars_from_ids(predicted_ids)\n",
        "\n",
        "        # Return the characters and model state.\n",
        "        return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfuZisi5ZSKs",
        "outputId": "dcf95d3f-496a-4eac-cac3-1c2eac45e516"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['dance'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "    next_char, states = generate_one_step(model, next_char, states=states)\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([b'dancer miranda is a fredyfin serjon vile in our mirror bound wouldnt leav a sound if your wake in america and we found those thing we said fransilli of wretch togeth with tear are fall tear like the road to the bee part of them didnt take my breath you dirti thing consequ your your last time time seem for all thi sexi grey caus your laid park right your too backy act nearli broken new bottl ill rearrang for the day well i can see what youd fell apart the dog is you that i cant stand that sympathis with the bamboo off the corn the pric instit of color maset of cussa in high hors run out of control when the afternoon scotlers disconcert wife and famili and you dont care caus when will where it went without it listen to my wall a littl bit close confid wont no i will stand as deep so ill take you down so madli tight the king is burn on the answer are keep bring me id be glad to be thi old rage babi im a babi straight for i throw some twenti filth on the countri in jamazingl to beat the pitch s'], shape=(1,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.099931240081787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ3KNIfKhUOi"
      },
      "source": [
        "## Pop Genre\n",
        "#### Run-time ~ 25-30 mins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dbuz_svhYDo"
      },
      "source": [
        "lyric_pop = cleaned_data['cleanedlyrics'].loc[(cleaned_data['Genre']=='Pop')&(cleaned_data['Language']=='en')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG-pK2fghYDp"
      },
      "source": [
        "lyric_pop = lyric_pop.str.cat(sep=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ub5DdFhYDp",
        "outputId": "57a3f761-c834-47bb-eb8f-c211458226bc"
      },
      "source": [
        "print(f'Length of text: {len(lyric_pop)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 125333310 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UaK94BTghYDy",
        "outputId": "79b8b592-da54-485b-93b4-d3cee9c0d9dd"
      },
      "source": [
        "lyric_pop[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'twentyf year and my life is still tri to get up th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FESTJrWZhYDz",
        "outputId": "7cee4b21-950f-4576-f6d2-49ba95b4077a"
      },
      "source": [
        "# exract an ordered vocabulary - this will be letters, some numbers etc. \n",
        "vocab = sorted(set(lyric_pop))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVsE5wqPhYDz"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NOG5F89hYDz"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLMpIWNJhYDz"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X6MqmPyhYD0",
        "outputId": "918e4e24-8a66-4d57-dc5c-9d6d90f740c8"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(lyric_pop, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(125333310,), dtype=int64, numpy=array([22, 25,  7, ..., 17, 15,  7])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlpWPz4ghYD0"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy-9P6hLhYD0"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(lyric_pop)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI9vEXtehYD0"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ojVo7HhYD0"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66xPcVFPhYD0"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXwXxGvKhYD1",
        "outputId": "5d818658-ee30-410a-e437-fa7753622b75"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'twentyf year and my life is still tri to get up that great big hill of hope for a destin i realiz qu'\n",
            "Target: b'wentyf year and my life is still tri to get up that great big hill of hope for a destin i realiz qui'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy02yIVChYD1",
        "outputId": "fee4e65b-788e-43a9-d3cd-88413de5ef94"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((256, 100), (256, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTvKyq17hYD1"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFleTTchYD1"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krgX24jnhYD1"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtWhnkD5hYD1",
        "outputId": "b3573ec9-6bd8-45f2-ace6-2f246eeb024b"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 100, 69) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "scrolled": false,
        "id": "vh-4wTfuhYD2",
        "outputId": "32a1ef99-828c-4a8e-dd9b-227ff2005547"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  17664     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  70725     \n",
            "=================================================================\n",
            "Total params: 4,026,693\n",
            "Trainable params: 4,026,693\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDVp5zS3hYD2"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZYQ52-hYD2"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGf9tDO-hYD2"
      },
      "source": [
        "EPOCHS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Or6NC31hYD2",
        "outputId": "5f774a7e-bf6a-452f-e461-e5eff5c48c1e"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS,callbacks=[checkpoint_callback],verbose=1)\n",
        "print(\"training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4847/4847 [==============================] - 963s 198ms/step - loss: 1.5145\n",
            "Epoch 2/2\n",
            "4847/4847 [==============================] - 960s 198ms/step - loss: 1.1126\n",
            "training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyxgQRdXhYD2"
      },
      "source": [
        "def generate_one_step(model, inputs, states=None, temperature = 1):\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "        skip_ids = ids_from_chars(['', '[UNK]'])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "            # Put a -inf at each bad index.\n",
        "            values=[-float('inf')]*len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            # Match the shape to the vocabulary\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "        prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "        \n",
        "    # Convert strings to token IDs.\n",
        "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "        input_ids = ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        # Run the model.\n",
        "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "        predicted_logits, states = model(inputs=input_ids, states=states,\n",
        "                                              return_state=True)\n",
        "        # Only use the last prediction.\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits/temperature\n",
        "        # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "        predicted_logits = predicted_logits + prediction_mask\n",
        "\n",
        "        # Sample the output logits to generate token IDs.\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "        # Convert from token ids to characters\n",
        "        predicted_chars = chars_from_ids(predicted_ids)\n",
        "\n",
        "        # Return the characters and model state.\n",
        "        return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0H-ymKhhYD2",
        "outputId": "25be52b7-98b0-4b1c-fb4b-a78051b481e3"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['dance'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "    next_char, states = generate_one_step(model, next_char, states=states)\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([b'danced painki brokin and rocki ni chica head hod ass nigga you search for myself what cheas u you you wear my hair deep deep in my face and left from my pave my crime to my place and a jamman they hang me get real fast what you make me tri that i had a hacu i know the day what i can chang can i be with you more than and i give my dimnt up poliss and you can turn around and breakawatch a bodi on each other sign i wish i took a while suddenli im tire of not a mess chain so babi you turn around i tri to tear you over you you say come around he move darl you give me your love i can see your throli no matter what you do now be treat my leav you give your love to me thi right where is bright green me so what are we gonna do whatch it gonna choic hasit sugar yo to help her out a hit background i dream drip oh kbock the cold and you leav her meet need is a talk unaboda when you touch it move your face high lifer in need more fubutti all thi diamond in the acr no put thi love in the end iz nigga you'], shape=(1,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.202037334442139\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}